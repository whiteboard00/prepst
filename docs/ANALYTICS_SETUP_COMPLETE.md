# üéâ Learning Analytics System - Setup Complete!

## ‚úÖ What's Been Implemented

### 1. Session Completion Flow ‚úÖ

**File:** `frontend/app/practice/[sessionId]/summary/page.tsx`

When users finish a practice session and view the summary:

- ‚úÖ Automatically calls `/api/practice-sessions/{id}/complete` endpoint
- ‚úÖ Creates a performance snapshot with predicted SAT scores
- ‚úÖ Logs completion event
- ‚úÖ Non-blocking (UI still works if completion fails)

**What happens:**

```javascript
useEffect(() => {
  const completeSessionOnMount = async () => {
    const result = await api.completeSession(sessionId);
    // Logs predicted SAT Math & R/W scores
    // Creates performance snapshot
  };
  completeSessionOnMount();
}, [sessionId]);
```

### 2. Data Monitoring System ‚úÖ

**Files Created:**

- `backend/supabase/monitoring_queries.sql` - 12 comprehensive SQL queries
- `backend/scripts/check_analytics.py` - Python health check script
- `backend/scripts/test_analytics.sh` - Quick test script
- `backend/supabase/MONITORING_README.md` - Complete monitoring guide

## üöÄ How to Use

### Quick Health Check

```bash
cd backend
python3 scripts/check_analytics.py
```

This shows you:

- üìä User skill mastery tracking
- ‚è±Ô∏è Confidence & timing data collection
- üìù Learning events log
- üì∏ Performance snapshots
- üìà User progress summary
- üéØ Question difficulty calibration

### Run All Tests

```bash
cd backend
./scripts/test_analytics.sh
```

### Detailed SQL Queries

Open `backend/supabase/monitoring_queries.sql` and run any of these queries in your Supabase SQL Editor:

#### 1. Check Mastery Tracking

```sql
SELECT
  u.email,
  t.name as topic,
  usm.mastery_probability,
  usm.total_attempts,
  usm.correct_attempts,
  usm.learning_velocity,
  usm.plateau_flag
FROM user_skill_mastery usm
JOIN users u ON u.id = usm.user_id
JOIN topics t ON t.id = usm.skill_id
ORDER BY usm.mastery_probability ASC;
```

#### 2. Check Confidence/Timing Data

```sql
SELECT
  COUNT(*) as total_answered,
  AVG(confidence_score) as avg_confidence,
  AVG(time_spent_seconds) as avg_time_seconds
FROM session_questions
WHERE confidence_score IS NOT NULL;
```

#### 3. Check Learning Events

```sql
SELECT
  event_type,
  COUNT(*) as count
FROM learning_events
GROUP BY event_type;
```

## üìä 12 Monitoring Queries Available

1. **User Skill Mastery Tracking** - See mastery levels for each user/topic
2. **Confidence & Timing Data** - Verify data collection is working
3. **Learning Events Log** - Check what events are being logged
4. **Performance Snapshots** - View all snapshots created
5. **User Progress Summary** - Comprehensive progress overview
6. **Topic Difficulty Analysis** - IRT difficulty parameters
7. **Recent Learning Events** - Detailed user progression
8. **Skills Needing Attention** - Low mastery skills (< 0.5)
9. **High Performers** - High mastery skills (> 0.8)
10. **Confidence vs Performance** - Correlation analysis
11. **Session Completion Stats** - Completion tracking
12. **Learning Velocity Trends** - Fastest learning skills

## üß™ Testing the Complete Flow

### Step 1: Start Backend

```bash
cd backend
python -m uvicorn app.main:app --reload
```

### Step 2: Start Frontend

```bash
cd frontend
npm run dev
```

### Step 3: Test User Flow

1. **Start a practice session**

   - Go to study plan
   - Click "Start Practice"

2. **Answer questions**

   - Select answers
   - Optionally rate confidence (1-5 stars)
   - Click "Check Answer"
   - System tracks:
     - ‚úÖ Confidence score (defaults to 3)
     - ‚úÖ Time spent on question
     - ‚úÖ Correct/incorrect status
     - ‚úÖ BKT mastery update

3. **Complete session**
   - Navigate to summary page
   - System automatically:
     - ‚úÖ Calls completion endpoint
     - ‚úÖ Creates performance snapshot
     - ‚úÖ Logs predicted SAT scores

### Step 4: Verify Data

```bash
cd backend
python3 scripts/check_analytics.py
```

Or run specific queries in Supabase SQL Editor.

## üîç What to Look For

### Expected Data Flow:

1. **User answers question** ‚Üí

   - `session_questions` updated with confidence/timing
   - `user_skill_mastery` updated via BKT
   - `learning_events` logs "mastery_updated"

2. **User completes session** ‚Üí

   - `practice_sessions.status` = 'completed'
   - `user_performance_snapshots` created
   - Predicted SAT scores calculated

3. **Over time** ‚Üí
   - `learning_velocity` tracks improvement rate
   - `plateau_flag` identifies learning plateaus
   - `question_difficulty_params` calibrates via IRT

## üìà Key Metrics Dashboard

### User Progress

```sql
-- See in monitoring_queries.sql - Query #5
-- Shows avg mastery, accuracy, plateau skills
```

### Confidence Analysis

```sql
-- See in monitoring_queries.sql - Query #10
-- Shows accuracy per confidence level
```

### Learning Velocity

```sql
-- See in monitoring_queries.sql - Query #12
-- Shows which skills are learned fastest
```

## üêõ Troubleshooting

### No Mastery Records?

**Check:**

- Backend is running
- BKT service has no errors
- Users have answered questions

**Fix:**

```bash
# Check backend logs
cd backend
tail -f logs/app.log

# Verify endpoint works
curl -X PATCH http://localhost:8000/api/practice-sessions/{id}/questions/{qid}
```

### No Confidence Scores?

**Check:**

- Frontend confidence component is rendering
- Network requests include confidence_score
- Browser console for errors

**Fix:**

- Verify `ConfidenceRating` component in `AnswerPanel`
- Check network tab for PATCH requests
- Ensure `confidence_score` in request body

### No Performance Snapshots?

**Check:**

- Summary page is calling completion endpoint
- Backend completion endpoint works
- Supabase has no errors

**Fix:**

```bash
# Test endpoint directly
curl -X POST http://localhost:8000/api/practice-sessions/{id}/complete \
  -H "Authorization: Bearer {token}"
```

## üìö Additional Resources

- **Full Implementation Details:** `BKT_IMPLEMENTATION_SUMMARY.md`
- **Monitoring Guide:** `backend/supabase/MONITORING_README.md`
- **All SQL Queries:** `backend/supabase/monitoring_queries.sql`
- **Health Check Script:** `backend/scripts/check_analytics.py`

## üéØ Next Steps

Now that monitoring is set up, you can:

1. **Build Analytics Dashboard**

   - Use queries from `monitoring_queries.sql`
   - Create visualizations for growth curves
   - Display skill mastery heatmaps

2. **Optimize Learning Algorithms**

   - Monitor learning velocity
   - Identify plateau patterns
   - Adjust BKT parameters

3. **Enhance Adaptive Features**

   - Use IRT difficulty for question selection
   - Implement "desirable difficulty" targeting
   - Add spaced repetition scheduling

4. **Export Data for Analysis**
   - Export mastery data to CSV
   - Run external analytics
   - A/B test different approaches

## üí° Pro Tips

1. **Run health checks regularly**

   ```bash
   cd backend && python3 scripts/check_analytics.py
   ```

2. **Monitor confidence patterns**

   - High confidence + wrong = overconfidence
   - Low confidence + correct = need encouragement

3. **Track learning velocity**

   - Accelerating = good teaching method
   - Decelerating = plateau detected
   - Negative = possible regression

4. **Use snapshots for progress reports**
   - Weekly progress emails
   - Achievement unlocks
   - Personalized recommendations

---

## ‚úÖ System Status: OPERATIONAL

Your learning analytics system is now fully operational! üéâ

Start using your app, answer some questions, and then run the monitoring queries to see the magic happen. üöÄ
